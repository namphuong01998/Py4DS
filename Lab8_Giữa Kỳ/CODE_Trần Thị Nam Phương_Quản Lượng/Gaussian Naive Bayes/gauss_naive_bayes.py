# -*- coding: utf-8 -*-
"""Gauss Naive Bayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l-BAFzh6v4dY6fF9dPCdejBNzfhHLncl
"""

import numpy as np
import math
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB, MultinomialNB
from sklearn.metrics import accuracy_score
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)
print("X_train")
print(X_train)
print("y_train")
print(y_train)
#'''

'''
import numpy as np
import math
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import GaussianNB, MultinomialNB
rng = np.random.RandomState(42)
nPond = 20
nFeature = 100
nTest = 5
X_train = rng.randint(5, size=(nPond, nFeature))
y_train = rng.randint(5,size=nPond)
X_test = rng.randint(3, size=(nTest,nFeature))
'''

Class,Count = np.unique(y_train, return_counts = True)
print("Class and Count")
print(Class)
print(Count)

'''
function: GaussCalc
Purpose: Calculation log P(value of feature kth|class) by gauss
Input:
  - X: train set data
  - y: train set class
  - Class: array of name class
  - k: feature kth
  - value: value to calculation
  - c: index class in Class array
Output: Result log P(value of feature kth|class) by gauss
'''
def GaussCalc(X,y,Class,k,value,c):
  #Get feature of class Class[c]
  feature_c = []
  for i in range(X_train.shape[0]):
    if (y[i] == Class[c]):
      feature_c.append(X_train[i][k]);
  #print(feature_c)
  # Calculation EX and VAR
  EX = 0
  EX2 = 0
  VAR = 0
  for i in range(len(feature_c)):
    EX = EX + feature_c[i]
    EX2 = EX2 + pow(feature_c[i],2)
  EX = EX / len(feature_c)
  EX2 = EX2 / len(feature_c)
  VAR = EX2-pow(EX,2)
  if (VAR==0):
    VAR = 1e-9
  #print(EX)
  #print(VAR)
  #print(value)
  # caculation result
  res = -math.log(math.sqrt(2*math.pi*VAR))-pow(value-EX,2)/(2*VAR)
  return res

y_pred = []
for i in range(len(X_test)):
  max_value_C = -100000000
  max_position = -1
  for j in range(len(Class)): # c = Class[i]
    # tinh argmax p(c|X_test[i]) = argmax p(X_test[i]|c)*p(c) = argmax ln(p(X_test[i]|c))+argmax(p(c))
    p_c = math.log(Count[j]/len(y_train))
    #tinh argmax p(X_test[i]|c) = argmax product(p(X_test[i][j]|c)) = argmax sum ln(p(X_test[i][j]|c))
    product = 0;
    for k in range(X_train.shape[1]):
      product = product + GaussCalc(X_train,y_train,Class,k,X_test[i][k],j)
    value_C = p_c+product
    if (value_C> max_value_C):
      max_value_C = value_C
      max_position = j
  y_pred.append(Class[max_position])

print("Self Build model:")
print(y_pred)
#print(accuracy_score(y_test,y_pred))

print("Sklearn GaussianNB:")
gnb = GaussianNB()
y_pred = gnb.fit(X_train, y_train).predict(X_test)
print(y_pred)
#print(accuracy_score(y_test,y_pred))

